{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training linear nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num GPUs 0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib notebook\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from include import *\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "GPU = True\n",
    "if GPU == True:\n",
    "    torch.backends.cudnn.enabled = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    dtype = torch.cuda.FloatTensor\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "    print(\"num GPUs\",torch.cuda.device_count())\n",
    "else:\n",
    "    dtype = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_error_deep_decoder(img_np,net,net_input,convert2ycbcr=False):\n",
    "    '''\n",
    "    mse obtained by representing img_np with the deep decoder\n",
    "    '''\n",
    "    output_depth = img_np.shape[0]\n",
    "    if output_depth == 3 and convert2ycbcr:\n",
    "        img = rgb2ycbcr(img_np)\n",
    "    else:\n",
    "        img = img_np\n",
    "    img_var = np_to_var(img).type(dtype)\n",
    "    \n",
    "    rnd = 500\n",
    "    numit = 2500\n",
    "    rn = 0.005\n",
    "    mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=rn,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = rnd,\n",
    "                        num_iter=numit,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                               )\n",
    "    out_img = net(ni.type(dtype)).data.cpu().numpy()[0]\n",
    "    if output_depth == 3 and convert2ycbcr:\n",
    "        out_img = ycbcr2rgb(out_img)\n",
    "    return psnr(out_img,img_np), out_img, num_param(net)\n",
    "\n",
    "\n",
    "def myimgshow(plt,img):\n",
    "    if(img.shape[0] == 1):\n",
    "        plt.imshow(np.clip(img[0],0,1),cmap='Greys',interpolation='none')\n",
    "    else:\n",
    "        plt.imshow(np.clip(img.transpose(1, 2, 0),0,1),interpolation='none')    \n",
    "        \n",
    "def comparison(img_np,net,net_input,convert2ycbcr=False):\n",
    "    # compute representations\n",
    "    psnrv, out_img_np, nparms = rep_error_deep_decoder(img_np,net=net,net_input=net_input,convert2ycbcr=convert2ycbcr)\n",
    "    nchannels = img_np.shape[0]\n",
    "    \n",
    "    print(\"Compression factor: \", np.prod( img_np.shape ) / nparms )\n",
    "    # plot results\n",
    "    fig = plt.figure(figsize = (15,15)) # create a 5 x 5 figure \n",
    "    \n",
    "    ax1 = fig.add_subplot(131)\n",
    "    myimgshow(ax1,img_np) \n",
    "    ax1.set_title('Original image')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(132)\n",
    "    myimgshow(ax2,out_img_np)\n",
    "    ax2.set_title( \"Deep-Decoder representation, PSNR: %.2f\" % psnrv )\n",
    "    ax2.axis('off')\n",
    "    #save_np_img(img_np,\"exp_comp_orig.png\")\n",
    "    #save_np_img(out_img_np,\"exp_comp_dd.png\")\n",
    "    \n",
    "    plt.axis('off')\n",
    "    fig.show()\n",
    "    \n",
    "def plot_kernels(tensor):\n",
    "    if not len(tensor.shape)==4:\n",
    "        raise Exception(\"assumes a 4D tensor\")\n",
    "    num_kernels = tensor.shape[0]\n",
    "    fig = plt.figure(figsize=(tensor.shape[0],tensor.shape[1]))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        for j in range(tensor.shape[1]):\n",
    "            ax1 = fig.add_subplot(tensor.shape[0],tensor.shape[1],1+i*tensor.shape[0]+j)\n",
    "            ax1.imshow(tensor[i][j])\n",
    "            ax1.axis('off')\n",
    "            ax1.set_xticklabels([])\n",
    "            ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "def apply_until(net_input,net,n = 100):\n",
    "    # applies function by funtion of a network\n",
    "    for i,fun in enumerate(net):\n",
    "        if i>=n:\n",
    "            break\n",
    "        if i==0:\n",
    "            out = fun(net_input.type(dtype))\n",
    "        else:\n",
    "            out = fun(out)\n",
    "    print(i, \"last func. applied:\", net[i-1])\n",
    "    if n == 0:\n",
    "        return net_input\n",
    "    else:\n",
    "        return out\n",
    "\n",
    "def plot_tensor(out,nrows=8):\n",
    "    imgs = [img for img in out.data.cpu().numpy()[0]]\n",
    "    fig = plot_image_grid(imgs,nrows=nrows)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual batch norm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_batch_norm(X, gamma, beta, eps = 1e-5):\n",
    "    if len(X.shape) not in [4]:\n",
    "        raise ValueError('only supports 2dconv')\n",
    "    # extract the dimensions\n",
    "    N, C, H, W = X.shape\n",
    "    # mini-batch mean\n",
    "    mean = torch.mean(X, axis=(0, 2, 3))\n",
    "    # mini-batch variance\n",
    "    variance = torch.mean((X - mean.reshape((1, C, 1, 1))) ** 2, axis=(0, 2, 3))\n",
    "    # normalize\n",
    "    X_hat = (X - mean.reshape((1, C, 1, 1))) * 1.0 / torch.sqrt(variance.reshape((1, C, 1, 1)) + eps)\n",
    "    # scale and shift\n",
    "    return gamma.reshape((1, C, 1, 1)) * X_hat + beta.reshape((1, C, 1, 1))\n",
    "\n",
    "\n",
    "\n",
    "class ChannelNormalization(torch.nn.Module):\n",
    "    def __init__(self, D_in,mode=\"BN\"):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate two nn.Linear modules and assign them as\n",
    "        member variables.\n",
    "        \"\"\"\n",
    "        self.mode = mode\n",
    "        requires_grad=True\n",
    "        super(ChannelNormalization, self).__init__()\n",
    "        #self.gamma = Variable(torch.ones(D_in),requires_grad=requires_grad).type(dtype)\n",
    "        #self.beta = Variable(torch.zeros(D_in),requires_grad=requires_grad).type(dtype)\n",
    "        self.gamma = nn.Parameter(torch.ones(D_in))\n",
    "        self.beta = nn.Parameter(torch.zeros(D_in))\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        In the forward function we accept a Tensor of input data and we must return\n",
    "        a Tensor of output data. We can use Modules defined in the constructor as\n",
    "        well as arbitrary operators on Tensors.\n",
    "        \"\"\"\n",
    "        \n",
    "        #return (x - torch.mean(x))/(torch.std(x) + 0.00000001 ) *self.gamma[0] + self.beta[0]\n",
    "        \n",
    "        #return pure_batch_norm(x, self.gamma, self.beta, eps = 1e-5)\n",
    "        \n",
    "        xx = Variable(torch.zeros(x.shape)).type(dtype)\n",
    "        for i,(g,b) in enumerate(zip(self.gamma,self.beta)):\n",
    "            #print(i, x[0][i].shape)\n",
    "            if self.mode == \"BN\":\n",
    "                #xx[:,i] = (x[:,i] - torch.mean(x[:,i]))/(torch.std(x[:,i]) + 0.00000001 ) *g + b\n",
    "                #print(torch.mean(x[0][i]))\n",
    "                xx[0][i] = (x[0][i] - torch.mean(x[0][i]))/torch.sqrt( torch.var(x[0][i]) + 0.00001 ) * g + b\n",
    "                #xx[0][i] = (x[0][i] - torch.mean(x[0]))/(torch.std(x[0]) + 0.00000001 ) *g + b\n",
    "            elif self.mode == \"mult\":\n",
    "                xx[:,i] = x[:,i]*g + b\n",
    "            elif self.mode == \"non-learned\":\n",
    "                xx[0][i] = (x[0][i] - torch.mean(x[0][i]))/torch.sqrt( torch.var(x[0][i]) + 0.00001 )\n",
    "            elif self.mode == \"center\":\n",
    "                xx[:,i] = (x[:,i] - torch.mean(x[:,i]))\n",
    "            elif self.mode == \"normalize+bias\":\n",
    "                xx[0][i] = (x[0][i])/torch.sqrt( torch.var(x[0][i]) + 0.00001 ) * g + b\n",
    "            elif self.mode == \"only+bias\":\n",
    "                xx[:,i] = x[:,i] + b\n",
    "            elif self.mode == \"onlycenter+bias\":\n",
    "                xx[:,i] = (x[:,i] - torch.mean(x[:,i]))*g + b\n",
    "            elif self.mode == \"almostcenter\":\n",
    "                xx[:,i] = ( (x[:,i] - torch.mean(x[:,i])) + torch.mean(x[:,i]) / torch.from_numpy( np.sqrt( np.array([np.prod(x[0][i].shape)]) ) ).float().type(dtype)) /torch.sqrt( torch.var(x[0][i]) + 0.00001 ) + b\n",
    "            elif self.mode == \"center+scale\":\n",
    "                #xx[:,i] =  (x[:,i] - torch.mean(x[:,i])) / (torch.max( x[:,i] - torch.mean(x[:,i]) )  - torch.min( x[:,i] - torch.mean(x[:,i]) ) )\n",
    "                xx[:,i] =  (x[:,i] - torch.mean(x[:,i])) / (torch.max( torch.abs(x[:,i] - torch.mean(x[:,i]) ) ) + 0.00001)\n",
    "            elif self.mode == \"center+mean_scale\":\n",
    "                xx[:,i] =  (x[:,i] - torch.mean(x[:,i])) / torch.mean(torch.abs( x[:,i] - torch.mean(x[:,i]) ) )\n",
    "            elif self.mode == \"noise\":\n",
    "                #   noise = Variable(ins.data.new(ins.size()).normal_(mean, stddev))\n",
    "                #no = torch.norm(x[0][i].data)\n",
    "                #sigma = 0.1*no\n",
    "                #noise = Variable( torch.randn( x[0][i].size() ) * sigma ).type(dtype)\n",
    "                #noise = Variable( x[0][i].data.new(x[0][i].size()).normal_(0, sigma))\n",
    "                xx[0][i] = x[0][i] / ( torch.norm(x[0][i])* np.prod(x[0][i].shape) + 0.00001  ) + b\n",
    "                #xx[0][i] = x[0][i] / torch.norm( x[0][i] )  + noise + b\n",
    "                #xx[0][i] = (x[0][i] - torch.mean(x[0][i])) / torch.sqrt( torch.var(x[0][i]) + 0.00001 ) + b\n",
    "            #elif self.mode == \"center_then_normalize\": # stupid; is the same as BN\n",
    "            #    center =  (x[0][i] - torch.mean(x[0][i]))\n",
    "            #    xx[0][i] = center / torch.sqrt( torch.var(center) + 0.00001 ) + b\n",
    "            elif self.mode == \"scale\":\n",
    "                z =  x[0][i]\n",
    "                xx[0][i] = z / ( torch.norm(z) + 0.00001 )*g + b\n",
    "            else:\n",
    "                raise ValueError('not an option for channel normalization.')\n",
    "        return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = ChannelNormalization(4)\n",
    "#m.parameters()\n",
    "#print('m', list(m.parameters()))\n",
    "\n",
    "def init_normal(m):\n",
    "    if type(m) == nn.Conv2d:\n",
    "        nn.init.xavier_uniform(m.weight)\n",
    "\n",
    "# use the modules apply function to recursively apply the initialization\n",
    "#rand_net.apply(init_normal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder with channel normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv(in_f, out_f, kernel_size, stride=1, pad='zero',bias=False):\n",
    "    padder = None\n",
    "    to_pad = int((kernel_size - 1) / 2)\n",
    "    if pad == 'reflection':\n",
    "        padder = nn.ReflectionPad2d(to_pad)\n",
    "        to_pad = 0\n",
    "  \n",
    "    convolver = nn.Conv2d(in_f, out_f, kernel_size, stride, padding=to_pad, bias=bias)\n",
    "\n",
    "    layers = filter(lambda x: x is not None, [padder, convolver])\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def decnet(\n",
    "        num_output_channels=3, \n",
    "        num_channels_up=[128]*5, \n",
    "        filter_size_up=1,\n",
    "        act_fun=nn.ReLU(), # nn.LeakyReLU(0.2, inplace=True) \n",
    "        mode = \"mult\",\n",
    "        ):\n",
    "    \n",
    "    num_channels_up = num_channels_up + [num_channels_up[-1]]\n",
    "    n_scales = len(num_channels_up) \n",
    "    \n",
    "    model = nn.Sequential()\n",
    "\n",
    "    \n",
    "    for i in range(len(num_channels_up)-1):\n",
    "        model.add(conv( num_channels_up[i], num_channels_up[i+1],  filter_size_up, 1, pad='reflection'))        \n",
    "        #model.add(act_fun)\n",
    "        #model.add(nn.BatchNorm2d( num_channels_up[i+1] ,affine=True))\n",
    "        model.add(ChannelNormalization(num_channels_up[i+1],mode=mode))\n",
    "        #model.add(nn.BatchNorm2d( num_channels_up[i+1] ,affine=True,track_running_stats=False,momentum=0))                 \n",
    "    \n",
    "    model.add(conv( num_channels_up[-1], num_output_channels, 1, pad='reflection',bias=True))\n",
    "    model.add(nn.Sigmoid())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1544199946412/work/aten/src/THC/THCGeneral.cpp:51",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aca69b9ea228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_to_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_pil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mimg_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_np\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_to_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (38) : no CUDA-capable device is detected at /opt/conda/conda-bld/pytorch_1544199946412/work/aten/src/THC/THCGeneral.cpp:51"
     ]
    }
   ],
   "source": [
    "path = './test_data/'\n",
    "img_name = \"phantom256\"\n",
    "img_path = path + img_name + \".png\"\n",
    "img_pil = Image.open(img_path)\n",
    "img_np = pil_to_np(img_pil)\n",
    "img_np = img_np / np.max(img_np)\n",
    "img_var = np_to_var(img_np).type(dtype)\n",
    "print(img_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Effect of normalization on norm of gradients\n",
    "\n",
    "The experiments shows that for this simple setup of only one convlayer and a linear problem, normalization efficiently avoids vanishing gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*10\n",
    "output_depth = 1\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"center+scale\").type(dtype)\n",
    "\n",
    "net.apply(init_normal)\n",
    "\n",
    "mse_n, mse_t, ni, net, out_grads = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=1000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        output_gradients=True,\n",
    "                               )\n",
    "\n",
    "for i,g in enumerate(out_grads):\n",
    "    plt.semilogy(g,label=str(i)) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*10\n",
    "output_depth = 1\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"center+mean_scale\").type(dtype)\n",
    "\n",
    "net.apply(init_normal)\n",
    "\n",
    "mse_n, mse_t, ni, net, out_grads = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=1000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        output_gradients=True,\n",
    "                               )\n",
    "\n",
    "for i,g in enumerate(out_grads):\n",
    "    plt.semilogy(g,label=str(i)) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in net.modules():\n",
    "    if isinstance(m, ChannelNormalization):\n",
    "        print(m.beta.data,m.gamma.data)\n",
    "#        print(torch.norm(m.weight.data).cpu())#p='fro')\n",
    "        #print(m.weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*10\n",
    "output_depth = 1\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"BN\").type(dtype)\n",
    "\n",
    "net.apply(init_normal)\n",
    "\n",
    "mse_n, mse_t, ni, net, out_grads = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=1000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        output_gradients=True,\n",
    "                               )\n",
    "\n",
    "for i,g in enumerate(out_grads):\n",
    "    plt.semilogy(g,label=str(i)) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*5\n",
    "output_depth = 1\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"only+bias\").type(dtype)\n",
    "net.apply(init_normal)\n",
    "\n",
    "mse_n, mse_t, ni, net, out_grads = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=1000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        output_gradients=True,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,g in enumerate(out_grads):\n",
    "    plt.semilogy(g,label=str(i)) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*10\n",
    "output_depth = 1\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"BN\").type(dtype)\n",
    "\n",
    "net.apply(init_normal)\n",
    "\n",
    "mse_n, mse_t, ni, net, out_grads = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=1000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        output_gradients=True,\n",
    "                               )\n",
    "\n",
    "for i,g in enumerate(out_grads):\n",
    "    plt.semilogy(g,label=str(i)) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,g in enumerate(out_grads):\n",
    "    plt.semilogy(g,label=str(i)) \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear net, with batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [8]*15\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decodernw(output_depth,num_channels_up=num_channels,upsample_mode='none',act_fun=None,filter_size_up=9).type(dtype)\n",
    "\n",
    "width = img_np.shape[1]\n",
    "height = img_np.shape[2]\n",
    "shape = [1,num_channels[0], width, height]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear net, without batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [8]*15\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decodernw(output_depth,num_channels_up=num_channels,upsample_mode='none',bn=False,act_fun=None,filter_size_up=9).type(dtype)\n",
    "\n",
    "width = img_np.shape[1]\n",
    "height = img_np.shape[2]\n",
    "shape = [1,num_channels[0], width, height]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [8]*15\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decodernw(output_depth,num_channels_up=num_channels,upsample_mode='none',bn=False,act_fun=None,filter_size_up=9).type(dtype)\n",
    "\n",
    "width = img_np.shape[1]\n",
    "height = img_np.shape[2]\n",
    "shape = [1,num_channels[0], width, height]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [8]*15\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"BN\").type(dtype)\n",
    "\n",
    "mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=100,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        #output_gradient=True,\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for m in net.modules():\n",
    "#    if isinstance(m, ChannelNormalization):\n",
    "#        print(\"parameters:\")\n",
    "#        print(m.gamma)\n",
    "#        print(m.beta)\n",
    "        #print(m.weights.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with different BN variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "\n",
    "num_channels = [8]*15\n",
    "output_depth = img_np.shape[0] # number of output channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"BN\").type(dtype)\n",
    "\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reparameterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_channels = [8]*15\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"mult\").type(dtype)\n",
    "\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Center and only learn bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"center+bias\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only center and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_channels = [8]*15\n",
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"onlycenter+bias\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"normalize+bias\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for m in net.modules():\n",
    "#    if isinstance(m, nn.Conv2d):\n",
    "#        print(m.weight.data.shape)\n",
    "#        print(torch.norm(m.weight.data).cpu())#p='fro')\n",
    "        #print(m.weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"only+bias\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = decnet(output_depth,num_channels,filter_size_up=9,mode=\"scale\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*10\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "net = decnet(output_depth,num_channels,filter_size_up=81,mode=\"BN\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*10\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"only+bias\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*1\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"only+bias\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        #print(m.weight.data.shape)\n",
    "        print(torch.norm(m.weight.data).cpu())#p='fro')\n",
    "        #print(m.weights.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"BN\").type(dtype)\n",
    "\n",
    "mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=1000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='SGD',\n",
    "                        output_gradients=True,\n",
    "                               )\n",
    "\n",
    "print(net)\n",
    "plt.semilogy(mse_n)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "for p in net.parameters():\n",
    "    print(len(p.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)\n",
    "\n",
    "for m in net.modules():\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Norms of gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = [x for x in net.parameters() ]\n",
    "img_var = np_to_var(img_np).type(dtype)\n",
    "mse = torch.nn.MSELoss()\n",
    "out = net(net_input.type(dtype))\n",
    "loss = mse(out, img_var)\n",
    "loss.backward()\n",
    "for p in list(filter(lambda p: p.grad is not None, net.parameters())):\n",
    "    print(p.grad.data.norm(2).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*2\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "net = decnet(output_depth,num_channels,filter_size_up=51,mode=\"BN\").type(dtype)\n",
    "comparison(img_np,net,net_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [1]*30\n",
    "output_depth = img_np.shape[0] # number of output channels\n",
    "net = decodernw(output_depth,num_channels_up=num_channels,upsample_mode='none',act_fun=None,filter_size_up=19).type(dtype)\n",
    "\n",
    "width = img_np.shape[1]\n",
    "height = img_np.shape[2]\n",
    "shape = [1,num_channels[0], width, height]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "#comparison(img_np,net,net_input)\n",
    "\n",
    "mse_n, mse_t, ni, net = fit( num_channels=num_channels,\n",
    "                        reg_noise_std=0.0,\n",
    "                        net_input=net_input.type(dtype),        \n",
    "                        reg_noise_decayevery = 500,\n",
    "                        num_iter=20000,\n",
    "                        #LR=0.005,\n",
    "                        LR=0.05,\n",
    "                        img_noisy_var=img_var,\n",
    "                        net=net,\n",
    "                        img_clean_var=img_var,\n",
    "                        find_best=False,\n",
    "                        OPTIMIZER='adam',\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = [4]*1\n",
    "net = decnet(3,num_channels).type(dtype)\n",
    "print(net)\n",
    "\n",
    "\n",
    "shape = [1,num_channels[0], img_np.shape[1], img_np.shape[2]]\n",
    "print(\"shape: \", shape)\n",
    "net_input = Variable(torch.zeros(shape))\n",
    "net_input.data.uniform_()\n",
    "net_input.data *= 1./10\n",
    "net(net_input.type(dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array( [[[[1,1],[1,1]], [[2,2],[2,2]] ] , [[[1,1],[1,1]], [[2,2],[2,2]] ] ] )\n",
    "print(A.shape)\n",
    "print(A)\n",
    "c = np.array([1,2])\n",
    "B = c * A \n",
    "print(B.shape)\n",
    "print(A[:,:,:]*c)\n",
    "\n",
    "print(A[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array( [ [[[1,1],[1,1]], [[2,2],[2,2]]] , [[[1,1],[1,1]], [[2,2],[2,2]]] ] )\n",
    "print(A.shape,A[0,0])\n",
    "c = np.array([1,2])\n",
    "\n",
    "for i,(a,b) in enumerate(zip(c,c)):\n",
    "    print(\"a: \", A[0,i])\n",
    "    A[:,i] = A[:,i]*a + b\n",
    "    \n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model1, self).__init__()\n",
    "        self.multp = Variable(torch.rand(1), requires_grad=True)\n",
    "\n",
    "class Model2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model2, self).__init__()\n",
    "        self.multp = nn.Parameter(torch.rand(1)) # requires_grad is True by default for Parameter\n",
    "\n",
    "m1 = Model1()\n",
    "m2 = Model2()\n",
    "\n",
    "print('m1', list(m1.parameters()))\n",
    "print('m2', list(m2.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
